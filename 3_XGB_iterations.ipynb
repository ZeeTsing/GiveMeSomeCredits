{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and treat missing values\n",
    "\n",
    "As observed in first iteration, the data is rather clean except some missing values\n",
    "\n",
    "The fact that only 12 features included in the data means that we may skip the process of feature selection but we could consider feature engineering if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from collections import Counter\n",
    "from helper_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score,roc_auc_score,accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'G:/Github/GiveMeSomeCredits/data/cs-training.csv'\n",
    "test_path = 'G:/Github/GiveMeSomeCredits/data/cs-test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path,index_col = 0).reset_index()\n",
    "df_test = pd.read_csv(test_path,index_col = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_and_preprocess(resample = 'ROS',scale = True):\n",
    "    #import\n",
    "    train_path = 'G:/Github/GiveMeSomeCredits/data/cs-training.csv'\n",
    "    test_path = 'G:/Github/GiveMeSomeCredits/data/cs-test.csv'\n",
    "    df_train = pd.read_csv(train_path,index_col = 0).reset_index()\n",
    "    df_test = pd.read_csv(test_path,index_col = 0).reset_index()\n",
    "    \n",
    "    #fill in NA\n",
    "    df_train = df_train.fillna(0)\n",
    "    df_test = df_test.fillna(0)\n",
    "    \n",
    "    y = df_train.SeriousDlqin2yrs\n",
    "    X = df_train.drop(columns=['SeriousDlqin2yrs','index'])\n",
    "    X_test = df_test.drop(columns=['SeriousDlqin2yrs','index'])\n",
    "    \n",
    "    assert resample\n",
    "    if resample == 'ROS':\n",
    "        X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_sample(X,y)\n",
    "    elif resample == \"SMOTE\":\n",
    "        X_resampled, y_resampled = SMOTE(random_state=0).fit_sample(X,y)\n",
    "    \n",
    "    if scale:\n",
    "        scaler = preprocessing.StandardScaler().fit(X_resampled)\n",
    "        X_train = scaler.transform(X_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train = X_resampled\n",
    "    \n",
    "    return X_train,y_resampled,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our first model which is a logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test = data_import_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = [0.9,1,2,3],cv = 5,penalty =  'l2',max_iter = 1000,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model,results = model_fit_train_score_skf(model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714 \n",
      "F1 score: 0.695 \n",
      "AUC score: 0.790\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, 10% improvement on AUC from the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = fitted_model.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/2nd_sub.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some insights from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['age' 'MonthlyIncome' 'DebtRatio' 'RevolvingUtilizationOfUnsecuredLines']\n",
      "\n",
      "Largest Coefs: \n",
      "['NumberOfTime30-59DaysPastDueNotWorse' 'NumberOfTimes90DaysLate'\n",
      " 'NumberOfTime60-89DaysPastDueNotWorse' 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "#get feature names from the dataframe\n",
    "feature_names = np.array(df_train.drop(columns=['SeriousDlqin2yrs','index']).columns)\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = fitted_model.coef_[0].argsort()\n",
    "\n",
    "# Find smallest and largest coefficients\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:4]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-5:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate=0.1, \n",
    "                    min_child_weight=3, \n",
    "                    colsample_bytree=0.9,\n",
    "                    objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model,results = model_fit_train_score_skf(clf,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789 \n",
      "F1 score: 0.787 \n",
      "AUC score: 0.869\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['Accuracy_mean']:.3f} \\nF1 score: {results['F1_mean']:.3f} \\nAUC score: {results['AUC_mean']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = fitted_model.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/3rd_sub.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22980771940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(fitted_model,importance_type='gain',show_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RevolvingUtilizationOfUnsecuredLines',\n",
       "       'NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTimes90DaysLate',\n",
       "       'NumberOfTime60-89DaysPastDueNotWorse',\n",
       "       'NumberRealEstateLoansOrLines', 'age',\n",
       "       'NumberOfOpenCreditLinesAndLoans', 'MonthlyIncome', 'DebtRatio',\n",
       "       'NumberOfDependents'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[[0,2,6,8,7,1,5,4,3,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kaggle score: 0.8670\n",
    "\n",
    "Can we improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([10.55895991, 13.97043834, 14.32429152, 11.28601456, 13.7222333 ,\n",
      "       11.8626718 , 10.17578464, 12.28973074, 10.86274648, 10.24898829,\n",
      "       11.95981212, 10.56357474,  9.76727581, 12.29592152, 11.20144038,\n",
      "       11.47191801, 11.60176969, 10.57571445, 11.38794241, 13.41056046,\n",
      "       12.55143075, 11.98953295, 13.76200576, 12.4142096 , 11.3346848 ,\n",
      "       13.71950636, 12.78620257, 11.87124829, 13.77755036, 12.63460784,\n",
      "       11.85401688, 13.92527099, 12.62583046, 12.30570478, 13.4839416 ,\n",
      "       12.3617383 , 13.09707713, 15.8858139 , 14.60435519, 13.76060128,\n",
      "       16.40244002, 15.2918283 , 14.69350095, 16.46596107, 15.07458487,\n",
      "       13.58537321, 15.69901118, 14.83492279, 13.84560614, 15.95732155,\n",
      "       14.60433898, 13.53580637, 15.58463888, 13.68929391]), 'std_fit_time': array([0.23292051, 1.77732804, 0.6902639 , 0.79537967, 0.14033206,\n",
      "       1.05774693, 0.2046242 , 0.11647685, 0.06183558, 0.15647441,\n",
      "       0.10987383, 0.16322649, 0.13413567, 0.21153537, 0.22459894,\n",
      "       0.38322914, 0.10378445, 0.32537708, 0.05528644, 0.14869505,\n",
      "       0.27713517, 0.20080643, 0.10107452, 0.15656599, 0.05319026,\n",
      "       0.24194072, 0.16995632, 0.0398027 , 0.09902187, 0.16149195,\n",
      "       0.03999356, 0.09112268, 0.27707008, 0.41440436, 0.0761939 ,\n",
      "       0.09222053, 0.17825527, 0.14111842, 0.0723544 , 0.0988627 ,\n",
      "       0.47846567, 0.47252535, 0.96344879, 0.64163758, 0.20775023,\n",
      "       0.14847453, 0.28647959, 0.11781853, 0.2847533 , 0.12965935,\n",
      "       0.25585242, 0.08259699, 0.09739511, 1.39354264]), 'mean_score_time': array([0.2044528 , 0.1753315 , 0.18849602, 0.18430705, 0.17014461,\n",
      "       0.16575704, 0.17213926, 0.18370848, 0.17453327, 0.1757297 ,\n",
      "       0.17553134, 0.16416111, 0.16715364, 0.18769832, 0.17573028,\n",
      "       0.17293715, 0.16695375, 0.16635518, 0.16974602, 0.16156816,\n",
      "       0.17094254, 0.1727385 , 0.16376152, 0.16735182, 0.16555705,\n",
      "       0.17732577, 0.17313685, 0.16755204, 0.17174191, 0.17134194,\n",
      "       0.1729373 , 0.16775155, 0.17553134, 0.18191462, 0.1651588 ,\n",
      "       0.16436014, 0.16994615, 0.16515946, 0.16555734, 0.16914864,\n",
      "       0.16376228, 0.16835041, 0.17573009, 0.16715307, 0.16376233,\n",
      "       0.17632885, 0.1625658 , 0.16914864, 0.16815014, 0.1685492 ,\n",
      "       0.16635594, 0.16456008, 0.16416082, 0.16954699]), 'std_score_time': array([0.02238167, 0.00410727, 0.03263536, 0.00736703, 0.00840679,\n",
      "       0.00385763, 0.00638913, 0.01761047, 0.00643287, 0.00791394,\n",
      "       0.00827362, 0.00257016, 0.00474562, 0.01426506, 0.008113  ,\n",
      "       0.00791899, 0.00421257, 0.00425018, 0.01348996, 0.00252261,\n",
      "       0.01521221, 0.0087718 , 0.0034206 , 0.00461034, 0.00189228,\n",
      "       0.01378162, 0.00845373, 0.00356812, 0.00551271, 0.00736664,\n",
      "       0.00875419, 0.00697875, 0.01969585, 0.01764514, 0.00552053,\n",
      "       0.00415478, 0.00768861, 0.00544775, 0.0035122 , 0.0044874 ,\n",
      "       0.00353499, 0.01447285, 0.00589657, 0.00444283, 0.00525466,\n",
      "       0.00768345, 0.00676437, 0.00924061, 0.00706911, 0.00413584,\n",
      "       0.00668704, 0.00383694, 0.00401934, 0.02338082]), 'param_colsample_bytree': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_leraning_rate': masked_array(data=[0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.01,\n",
      "                   0.01, 0.01, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.3, 0.3,\n",
      "                   0.3, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.01,\n",
      "                   0.01, 0.01, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.3, 0.3,\n",
      "                   0.3, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.01,\n",
      "                   0.01, 0.01, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.3, 0.3,\n",
      "                   0.3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5,\n",
      "                   0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2,\n",
      "                   0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9,\n",
      "                   0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5,\n",
      "                   0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9, 0.2, 0.5, 0.9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.5, 'leraning_rate': 0.0001, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.0001, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'subsample': 0.2}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.0001, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.0001, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'subsample': 0.2}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'subsample': 0.2}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'subsample': 0.9}], 'split0_test_score': array([0.86872289, 0.86890968, 0.8690526 , 0.86872289, 0.86890968,\n",
      "       0.8690526 , 0.86872289, 0.86890968, 0.8690526 , 0.86872289,\n",
      "       0.86890968, 0.8690526 , 0.86872289, 0.86890968, 0.8690526 ,\n",
      "       0.86872289, 0.86890968, 0.8690526 , 0.8692257 , 0.8692533 ,\n",
      "       0.86917148, 0.8692257 , 0.8692533 , 0.86917148, 0.8692257 ,\n",
      "       0.8692533 , 0.86917148, 0.8692257 , 0.8692533 , 0.86917148,\n",
      "       0.8692257 , 0.8692533 , 0.86917148, 0.8692257 , 0.8692533 ,\n",
      "       0.86917148, 0.86928004, 0.86951862, 0.86949252, 0.86928004,\n",
      "       0.86951862, 0.86949252, 0.86928004, 0.86951862, 0.86949252,\n",
      "       0.86928004, 0.86951862, 0.86949252, 0.86928004, 0.86951862,\n",
      "       0.86949252, 0.86928004, 0.86951862, 0.86949252]), 'split1_test_score': array([0.8676823 , 0.86778284, 0.86794289, 0.8676823 , 0.86778284,\n",
      "       0.86794289, 0.8676823 , 0.86778284, 0.86794289, 0.8676823 ,\n",
      "       0.86778284, 0.86794289, 0.8676823 , 0.86778284, 0.86794289,\n",
      "       0.8676823 , 0.86778284, 0.86794289, 0.8677559 , 0.86790265,\n",
      "       0.86806747, 0.8677559 , 0.86790265, 0.86806747, 0.8677559 ,\n",
      "       0.86790265, 0.86806747, 0.8677559 , 0.86790265, 0.86806747,\n",
      "       0.8677559 , 0.86790265, 0.86806747, 0.8677559 , 0.86790265,\n",
      "       0.86806747, 0.86830996, 0.86814187, 0.86831024, 0.86830996,\n",
      "       0.86814187, 0.86831024, 0.86830996, 0.86814187, 0.86831024,\n",
      "       0.86830996, 0.86814187, 0.86831024, 0.86830996, 0.86814187,\n",
      "       0.86831024, 0.86830996, 0.86814187, 0.86831024]), 'split2_test_score': array([0.86883607, 0.86878223, 0.8689801 , 0.86883607, 0.86878223,\n",
      "       0.8689801 , 0.86883607, 0.86878223, 0.8689801 , 0.86883607,\n",
      "       0.86878223, 0.8689801 , 0.86883607, 0.86878223, 0.8689801 ,\n",
      "       0.86883607, 0.86878223, 0.8689801 , 0.86924786, 0.86931115,\n",
      "       0.86919559, 0.86924786, 0.86931115, 0.86919559, 0.86924786,\n",
      "       0.86931115, 0.86919559, 0.86924786, 0.86931115, 0.86919559,\n",
      "       0.86924786, 0.86931115, 0.86919559, 0.86924786, 0.86931115,\n",
      "       0.86919559, 0.86916347, 0.86926162, 0.86935375, 0.86916347,\n",
      "       0.86926162, 0.86935375, 0.86916347, 0.86926162, 0.86935375,\n",
      "       0.86916347, 0.86926162, 0.86935375, 0.86916347, 0.86926162,\n",
      "       0.86935375, 0.86916347, 0.86926162, 0.86935375]), 'split3_test_score': array([0.8680062 , 0.86819775, 0.86845706, 0.8680062 , 0.86819775,\n",
      "       0.86845706, 0.8680062 , 0.86819775, 0.86845706, 0.8680062 ,\n",
      "       0.86819775, 0.86845706, 0.8680062 , 0.86819775, 0.86845706,\n",
      "       0.8680062 , 0.86819775, 0.86845706, 0.86806603, 0.86822773,\n",
      "       0.86846942, 0.86806603, 0.86822773, 0.86846942, 0.86806603,\n",
      "       0.86822773, 0.86846942, 0.86806603, 0.86822773, 0.86846942,\n",
      "       0.86806603, 0.86822773, 0.86846942, 0.86806603, 0.86822773,\n",
      "       0.86846942, 0.8682801 , 0.86863778, 0.86843613, 0.8682801 ,\n",
      "       0.86863778, 0.86843613, 0.8682801 , 0.86863778, 0.86843613,\n",
      "       0.8682801 , 0.86863778, 0.86843613, 0.8682801 , 0.86863778,\n",
      "       0.86843613, 0.8682801 , 0.86863778, 0.86843613]), 'split4_test_score': array([0.87118435, 0.8713542 , 0.87145107, 0.87118435, 0.8713542 ,\n",
      "       0.87145107, 0.87118435, 0.8713542 , 0.87145107, 0.87118435,\n",
      "       0.8713542 , 0.87145107, 0.87118435, 0.8713542 , 0.87145107,\n",
      "       0.87118435, 0.8713542 , 0.87145107, 0.87171818, 0.87169394,\n",
      "       0.8716968 , 0.87171818, 0.87169394, 0.8716968 , 0.87171818,\n",
      "       0.87169394, 0.8716968 , 0.87171818, 0.87169394, 0.8716968 ,\n",
      "       0.87171818, 0.87169394, 0.8716968 , 0.87171818, 0.87169394,\n",
      "       0.8716968 , 0.87150161, 0.87143076, 0.87161463, 0.87150161,\n",
      "       0.87143076, 0.87161463, 0.87150161, 0.87143076, 0.87161463,\n",
      "       0.87150161, 0.87143076, 0.87161463, 0.87150161, 0.87143076,\n",
      "       0.87161463, 0.87150161, 0.87143076, 0.87161463]), 'mean_test_score': array([0.86888636, 0.86900534, 0.86917674, 0.86888636, 0.86900534,\n",
      "       0.86917674, 0.86888636, 0.86900534, 0.86917674, 0.86888636,\n",
      "       0.86900534, 0.86917674, 0.86888636, 0.86900534, 0.86917674,\n",
      "       0.86888636, 0.86900534, 0.86917674, 0.86920273, 0.86927775,\n",
      "       0.86932015, 0.86920273, 0.86927775, 0.86932015, 0.86920273,\n",
      "       0.86927775, 0.86932015, 0.86920273, 0.86927775, 0.86932015,\n",
      "       0.86920273, 0.86927775, 0.86932015, 0.86920273, 0.86927775,\n",
      "       0.86932015, 0.86930704, 0.86939813, 0.86944145, 0.86930704,\n",
      "       0.86939813, 0.86944145, 0.86930704, 0.86939813, 0.86944145,\n",
      "       0.86930704, 0.86939813, 0.86944145, 0.86930704, 0.86939813,\n",
      "       0.86944145, 0.86930704, 0.86939813, 0.86944145]), 'std_test_score': array([0.00122756, 0.0012428 , 0.00120557, 0.00122756, 0.0012428 ,\n",
      "       0.00120557, 0.00122756, 0.0012428 , 0.00120557, 0.00122756,\n",
      "       0.0012428 , 0.00120557, 0.00122756, 0.0012428 , 0.00120557,\n",
      "       0.00122756, 0.0012428 , 0.00120557, 0.00139395, 0.00132914,\n",
      "       0.00126325, 0.00139395, 0.00132914, 0.00126325, 0.00139395,\n",
      "       0.00132914, 0.00126325, 0.00139395, 0.00132914, 0.00126325,\n",
      "       0.00139395, 0.00132914, 0.00126325, 0.00139395, 0.00132914,\n",
      "       0.00126325, 0.00117356, 0.00112437, 0.00118518, 0.00117356,\n",
      "       0.00112437, 0.00118518, 0.00117356, 0.00112437, 0.00118518,\n",
      "       0.00117356, 0.00112437, 0.00118518, 0.00117356, 0.00112437,\n",
      "       0.00118518, 0.00117356, 0.00112437, 0.00118518]), 'rank_test_score': array([49, 43, 37, 49, 43, 37, 49, 43, 37, 49, 43, 37, 49, 43, 37, 49, 43,\n",
      "       37, 31, 25, 13, 31, 25, 13, 31, 25, 13, 31, 25, 13, 31, 25, 13, 31,\n",
      "       25, 13, 19,  7,  1, 19,  7,  1, 19,  7,  1, 19,  7,  1, 19,  7,  1,\n",
      "       19,  7,  1])} {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 0.9} 0.8694414524423513\n"
     ]
    }
   ],
   "source": [
    "#grid search to optimize parameters\n",
    "param_test1 = {'leraning_rate':[0.0001,0.001,0.01,0.1,0.2,0.3],\n",
    "              'subsample':[0.2,0.5,0.9],\n",
    "              'colsample_bytree':[0.5,0.7,0.9]\n",
    "              }\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(objective='binary:logistic'),\n",
    "                      param_grid=param_test1,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = gsearch1.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/4th_sub.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kaggle private score: 0.8671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([14.3358202 , 15.06541452, 14.28704419, 16.26155663, 14.63413191,\n",
      "       14.06802382, 16.00872493, 14.60240397, 13.95230794, 16.0338213 ,\n",
      "       14.75759649, 14.01037316, 15.95724535, 14.7591023 , 14.02154055,\n",
      "       15.95157332, 14.65257626, 14.00421448, 16.0106173 , 14.66166639,\n",
      "       14.08419003, 15.99876947, 14.53740349, 14.14543118, 15.87189279,\n",
      "       14.48921142, 14.04258442, 15.98697081, 14.45769377, 13.92091203,\n",
      "       16.01309133, 14.5075603 , 13.91032667, 15.96473327, 14.46716328,\n",
      "       13.98606386, 16.07714243, 14.52113867, 13.88820486, 16.03714471,\n",
      "       14.42178674, 13.79003344, 16.03115458, 14.61105299, 13.87242818,\n",
      "       15.9413868 , 14.53558912, 13.89735436, 15.90248861, 14.54615746,\n",
      "       14.04758816, 15.96974969, 14.6509778 , 13.92607713, 15.85442061,\n",
      "       14.56291733, 13.90546584, 15.9390914 , 14.65249033, 13.92222548,\n",
      "       18.53750315, 17.25487518, 16.27077694, 18.62321286, 17.12113023,\n",
      "       16.29690351, 18.64077058, 17.13052588, 16.40674248, 18.71764917,\n",
      "       17.07158575, 16.3997354 , 18.78316841, 17.05703883, 16.39206576,\n",
      "       18.89388919, 17.0450531 , 16.51993575, 18.6440556 , 16.9226716 ,\n",
      "       16.30458717, 18.63814793, 17.09820428, 16.55453835, 18.58150301,\n",
      "       17.00585237, 16.40335989, 18.64028358, 16.89106646, 16.41860347,\n",
      "       18.74187975, 17.32072268, 16.36635089, 18.71407943, 17.17073407,\n",
      "       16.36852846, 18.63337102, 17.20263462, 16.25243888, 18.78155379,\n",
      "       17.20841713, 16.29742413, 18.76800771, 17.0775619 , 16.37662978,\n",
      "       18.69901414, 17.02960777, 16.37153726, 19.01373425, 17.0674016 ,\n",
      "       16.43647261, 18.59547977, 16.98789968, 16.52522593, 18.7201911 ,\n",
      "       17.07624917, 16.43308773, 18.59657526, 17.02310157, 16.51433043,\n",
      "       21.42438712, 19.71459222, 18.86692123, 21.4752378 , 19.66603231,\n",
      "       18.71082764, 21.62937703, 19.5658896 , 18.82679615, 21.52375102,\n",
      "       19.60747466, 18.8740941 , 21.63072982, 19.89182053, 18.96455445,\n",
      "       21.6018033 , 19.76063528, 18.8127542 , 21.75523963, 19.62503543,\n",
      "       18.865242  , 21.55373492, 19.59239531, 18.84457488, 21.4890388 ,\n",
      "       19.74251747, 18.83170648, 21.54446497, 19.74430852, 18.75030828,\n",
      "       21.56495924, 19.57139521, 18.92327662, 21.57111082, 19.53404999,\n",
      "       18.83950858, 21.4885294 , 19.80195217, 18.76800427, 21.57460165,\n",
      "       19.72205391, 18.82940779, 21.58517871, 19.49025807, 18.92056456,\n",
      "       21.54189959, 19.64225974, 18.95429363, 21.59713655, 19.96283679,\n",
      "       18.93944988, 21.60473943, 19.76495981, 18.81675806, 21.49112105,\n",
      "       19.75106926, 18.73924732, 21.41432171, 19.66260066, 18.80476918,\n",
      "       22.92887683, 21.07114344, 20.05908995, 22.96200967, 20.88615227,\n",
      "       20.03477015, 22.89733467, 21.27550983, 20.13479128, 23.12676024,\n",
      "       21.22876205, 20.08194809, 23.1132864 , 20.9436964 , 20.07284083,\n",
      "       22.89135332, 21.00373392, 20.02997274, 22.96167459, 21.21236076,\n",
      "       20.02197986, 22.92556572, 21.01137972, 20.03068023, 22.8746141 ,\n",
      "       21.06706119, 19.96598139, 23.02909269, 21.09938259, 20.06831145,\n",
      "       23.25231948, 21.10843263, 20.260745  , 22.90231342, 21.08889976,\n",
      "       19.97282605, 22.76588521, 20.98977327, 20.02150693, 23.00137258,\n",
      "       20.89896317, 20.03256497, 22.96645622, 20.98747349, 19.98579001,\n",
      "       22.91645799, 20.93778329, 19.86120682, 22.90871649, 20.89151382,\n",
      "       20.13578658, 23.02227559, 20.95955229, 20.02818241, 22.88229852,\n",
      "       20.94538755, 20.01858487, 23.08546443, 21.03761401, 18.7405602 ]), 'std_fit_time': array([1.22015129, 0.35307623, 0.17459411, 0.11828772, 0.05678515,\n",
      "       0.07063743, 0.07442288, 0.11305369, 0.05378555, 0.12685135,\n",
      "       0.18342492, 0.11070553, 0.08934017, 0.12078874, 0.07084463,\n",
      "       0.09517448, 0.19911509, 0.0708808 , 0.06250998, 0.17309565,\n",
      "       0.09752344, 0.08812703, 0.07590358, 0.13558507, 0.14195929,\n",
      "       0.15870073, 0.13731819, 0.1237156 , 0.1034722 , 0.15498743,\n",
      "       0.09342187, 0.14483932, 0.11507681, 0.09163074, 0.08498051,\n",
      "       0.15750033, 0.08766986, 0.10508469, 0.07355394, 0.11661049,\n",
      "       0.12018526, 0.0257654 , 0.16245752, 0.21691852, 0.09660745,\n",
      "       0.15974644, 0.1041271 , 0.03227373, 0.12597948, 0.15374441,\n",
      "       0.06226925, 0.07473892, 0.15150309, 0.09103234, 0.09371115,\n",
      "       0.16030392, 0.05159958, 0.12333723, 0.26318088, 0.12620346,\n",
      "       0.21381601, 0.13205673, 0.04311025, 0.0885766 , 0.19639615,\n",
      "       0.04672212, 0.1538628 , 0.21028788, 0.11135495, 0.06955378,\n",
      "       0.1358367 , 0.07422549, 0.20571685, 0.13592135, 0.09282927,\n",
      "       0.10899253, 0.13455506, 0.07703381, 0.12199054, 0.12288926,\n",
      "       0.07774779, 0.12556986, 0.09036155, 0.15141766, 0.16717538,\n",
      "       0.20918452, 0.1385062 , 0.1308868 , 0.22328426, 0.19979106,\n",
      "       0.15683671, 0.17538404, 0.033686  , 0.13224101, 0.14761771,\n",
      "       0.07705068, 0.1155364 , 0.08914883, 0.04877337, 0.16815924,\n",
      "       0.15448424, 0.11451097, 0.22589588, 0.13866854, 0.09728746,\n",
      "       0.14258743, 0.10506692, 0.18318009, 0.059999  , 0.08877569,\n",
      "       0.05667584, 0.10107579, 0.20078962, 0.11638291, 0.06497297,\n",
      "       0.10778562, 0.14180054, 0.10441668, 0.15698072, 0.18556304,\n",
      "       0.12097899, 0.1782139 , 0.13534104, 0.09100736, 0.02594397,\n",
      "       0.16004921, 0.12570811, 0.11991411, 0.16129153, 0.16024045,\n",
      "       0.11683652, 0.12018891, 0.10396752, 0.15645314, 0.11527628,\n",
      "       0.1183561 , 0.05685446, 0.07989416, 0.08633986, 0.05985619,\n",
      "       0.23425036, 0.13170964, 0.12177025, 0.09878022, 0.20705493,\n",
      "       0.12358732, 0.09110469, 0.17782058, 0.15013706, 0.08302241,\n",
      "       0.04669472, 0.08113467, 0.1315877 , 0.05246088, 0.06932404,\n",
      "       0.05083941, 0.0795206 , 0.12914215, 0.15261939, 0.13493532,\n",
      "       0.2190413 , 0.09948349, 0.09658389, 0.16948081, 0.12314142,\n",
      "       0.06995374, 0.15824779, 0.0962856 , 0.13588853, 0.25366826,\n",
      "       0.17907522, 0.0637356 , 0.0675009 , 0.10199443, 0.12882324,\n",
      "       0.03526747, 0.12157934, 0.07449959, 0.21982945, 0.08613598,\n",
      "       0.10833102, 0.06986765, 0.15222964, 0.13619949, 0.08025931,\n",
      "       0.14777196, 0.14219176, 0.15049418, 0.19300474, 0.07958811,\n",
      "       0.09658801, 0.12074852, 0.13004846, 0.11467102, 0.1512735 ,\n",
      "       0.13735534, 0.13627088, 0.15731907, 0.10526291, 0.06980575,\n",
      "       0.11435891, 0.10409697, 0.10409575, 0.15466046, 0.11226072,\n",
      "       0.2291179 , 0.12056561, 0.16870728, 0.12902679, 0.1139608 ,\n",
      "       0.13845808, 0.07153241, 0.09773991, 0.12770745, 0.15706892,\n",
      "       0.08803002, 0.08062091, 0.09789295, 0.18675778, 0.14954544,\n",
      "       0.11991674, 0.18620498, 0.18360956, 0.08774096, 0.11442276,\n",
      "       0.09450872, 0.12356273, 0.13757655, 0.09956152, 0.10791114,\n",
      "       0.10960878, 0.10864929, 0.14972767, 0.17834244, 0.05216167,\n",
      "       0.07912536, 0.04573204, 0.11269129, 0.06749291, 1.06181718]), 'mean_score_time': array([0.20576029, 0.22460918, 0.22560663, 0.2288969 , 0.22700329,\n",
      "       0.2276031 , 0.22500911, 0.2291966 , 0.22032008, 0.22012067,\n",
      "       0.21953821, 0.21762819, 0.23059874, 0.23787823, 0.21573243,\n",
      "       0.22510672, 0.22909627, 0.22091832, 0.22710242, 0.22640529,\n",
      "       0.21972256, 0.22072377, 0.21394782, 0.21583524, 0.22231503,\n",
      "       0.2203207 , 0.22740378, 0.22112117, 0.21723032, 0.22082162,\n",
      "       0.2227149 , 0.22321386, 0.21882577, 0.22510657, 0.22052135,\n",
      "       0.20935469, 0.21663346, 0.21742563, 0.2222177 , 0.21992464,\n",
      "       0.21882634, 0.2199214 , 0.22251844, 0.22271137, 0.22171588,\n",
      "       0.21613059, 0.21723061, 0.22591047, 0.22091866, 0.22341352,\n",
      "       0.22142   , 0.22730656, 0.22331109, 0.21553183, 0.22640595,\n",
      "       0.21493397, 0.21792564, 0.21912518, 0.21583514, 0.22221713,\n",
      "       0.2235127 , 0.21722937, 0.21673045, 0.21443486, 0.21852732,\n",
      "       0.21154232, 0.22430911, 0.21743493, 0.21723065, 0.22211628,\n",
      "       0.21652889, 0.22441134, 0.22092633, 0.21952271, 0.22611136,\n",
      "       0.22450814, 0.21832557, 0.22430882, 0.2191236 , 0.21723156,\n",
      "       0.22082028, 0.21593142, 0.22530808, 0.2276031 , 0.21743135,\n",
      "       0.21124763, 0.21802816, 0.21114473, 0.22500863, 0.21802897,\n",
      "       0.21932273, 0.22391076, 0.21942382, 0.21563764, 0.22520852,\n",
      "       0.21882815, 0.21533542, 0.21912394, 0.22311277, 0.21932259,\n",
      "       0.2254096 , 0.21453538, 0.22191844, 0.22161937, 0.21533761,\n",
      "       0.22032204, 0.21752806, 0.21752663, 0.2136415 , 0.22111988,\n",
      "       0.21084814, 0.22800164, 0.2169282 , 0.21134486, 0.22810054,\n",
      "       0.22740445, 0.22451611, 0.22151628, 0.22301335, 0.22281694,\n",
      "       0.22011991, 0.21812592, 0.22112217, 0.22690706, 0.22750077,\n",
      "       0.2143373 , 0.21653018, 0.22052155, 0.22031751, 0.21763182,\n",
      "       0.21014824, 0.21772661, 0.2143352 , 0.22012186, 0.21952295,\n",
      "       0.21513395, 0.21383839, 0.21563458, 0.21353946, 0.21732883,\n",
      "       0.21344109, 0.21523576, 0.21952138, 0.21823111, 0.21473684,\n",
      "       0.21513324, 0.21254263, 0.21812606, 0.21504049, 0.22072086,\n",
      "       0.22371612, 0.21204367, 0.22710428, 0.21732969, 0.22381234,\n",
      "       0.22131863, 0.22012224, 0.21723242, 0.21852751, 0.22740636,\n",
      "       0.22162085, 0.21713281, 0.21354251, 0.21014805, 0.2174314 ,\n",
      "       0.21412859, 0.22760444, 0.21035562, 0.21433806, 0.21703324,\n",
      "       0.21174483, 0.22570753, 0.21753173, 0.21104808, 0.21623363,\n",
      "       0.21234317, 0.2191237 , 0.2190269 , 0.22111783, 0.21623378,\n",
      "       0.21563702, 0.22800608, 0.2145371 , 0.22291422, 0.21902747,\n",
      "       0.22351313, 0.21364155, 0.22790537, 0.21792927, 0.2153347 ,\n",
      "       0.22251563, 0.22770157, 0.21782889, 0.22171712, 0.20974956,\n",
      "       0.21044846, 0.22351279, 0.226406  , 0.22301497, 0.22241631,\n",
      "       0.21304255, 0.21074519, 0.22760835, 0.22012281, 0.22860065,\n",
      "       0.21812673, 0.22231574, 0.21732783, 0.22710238, 0.21423936,\n",
      "       0.21852531, 0.21952362, 0.21573324, 0.21344013, 0.21194611,\n",
      "       0.20665908, 0.21274219, 0.21214447, 0.21294003, 0.22491336,\n",
      "       0.21902709, 0.21025028, 0.22201676, 0.22122107, 0.21563702,\n",
      "       0.22411499, 0.22131991, 0.21633067, 0.22181988, 0.21912413,\n",
      "       0.21463766, 0.21234512, 0.2249126 , 0.21344299, 0.22122111,\n",
      "       0.22540827, 0.22331777, 0.21025105, 0.21094575, 0.19279351]), 'std_score_time': array([0.00963632, 0.00859118, 0.00676439, 0.0075426 , 0.00564277,\n",
      "       0.01370896, 0.00790904, 0.01059129, 0.00402017, 0.00671711,\n",
      "       0.01373184, 0.0062066 , 0.01037185, 0.01484484, 0.01301013,\n",
      "       0.00461049, 0.00547645, 0.0087399 , 0.01073055, 0.00845295,\n",
      "       0.00870482, 0.00705539, 0.00570884, 0.00622805, 0.00838234,\n",
      "       0.01591497, 0.01278926, 0.00472585, 0.00792505, 0.00419143,\n",
      "       0.00529303, 0.01186496, 0.0040223 , 0.00781234, 0.01140003,\n",
      "       0.00874795, 0.00487936, 0.005284  , 0.00993404, 0.00157865,\n",
      "       0.00885792, 0.00467841, 0.01403115, 0.0056231 , 0.00711862,\n",
      "       0.00171639, 0.01045064, 0.00628163, 0.00649413, 0.01116882,\n",
      "       0.01085132, 0.00765714, 0.00495057, 0.01243451, 0.00942774,\n",
      "       0.00960706, 0.00977301, 0.00752638, 0.00803151, 0.00876398,\n",
      "       0.00683937, 0.00654358, 0.00781344, 0.00901685, 0.01540613,\n",
      "       0.00852346, 0.01122305, 0.01187047, 0.00339097, 0.01146441,\n",
      "       0.0081632 , 0.0031229 , 0.01074761, 0.00610305, 0.01110052,\n",
      "       0.02035841, 0.01078903, 0.01714327, 0.00517814, 0.00866095,\n",
      "       0.00794582, 0.00467837, 0.00863898, 0.00577278, 0.003483  ,\n",
      "       0.00548019, 0.00695502, 0.00711926, 0.01080762, 0.00715435,\n",
      "       0.00838267, 0.00512437, 0.00463693, 0.00639902, 0.01300704,\n",
      "       0.00924068, 0.00461658, 0.01071173, 0.00410856, 0.01281212,\n",
      "       0.00947574, 0.00507001, 0.00640367, 0.01211326, 0.01056401,\n",
      "       0.01075204, 0.00698449, 0.0052618 , 0.00779586, 0.01060035,\n",
      "       0.00700108, 0.00603984, 0.00699554, 0.01328452, 0.01494393,\n",
      "       0.01967061, 0.00896082, 0.00279199, 0.00816625, 0.00920792,\n",
      "       0.01396819, 0.01052354, 0.00990291, 0.00949388, 0.01509405,\n",
      "       0.00562778, 0.00974447, 0.0070698 , 0.01065027, 0.00514092,\n",
      "       0.00765806, 0.01010042, 0.00507129, 0.01310094, 0.0103578 ,\n",
      "       0.00525445, 0.00836062, 0.00438852, 0.01115268, 0.00619865,\n",
      "       0.00896815, 0.00267064, 0.01586529, 0.01636306, 0.00547677,\n",
      "       0.01065547, 0.01264108, 0.00965748, 0.01142581, 0.00576091,\n",
      "       0.01331204, 0.00485064, 0.02193744, 0.00430746, 0.01362924,\n",
      "       0.00675172, 0.00996148, 0.00781082, 0.00586875, 0.01244022,\n",
      "       0.01629918, 0.00435576, 0.0174657 , 0.00760636, 0.01089128,\n",
      "       0.00665563, 0.01867174, 0.00895105, 0.00530039, 0.01432868,\n",
      "       0.01180757, 0.00879317, 0.00745973, 0.00940183, 0.00734272,\n",
      "       0.00994417, 0.01244697, 0.00470649, 0.00683466, 0.00385976,\n",
      "       0.01261837, 0.00918918, 0.00544839, 0.00741072, 0.00974243,\n",
      "       0.00737207, 0.01128441, 0.00762899, 0.01421674, 0.0046602 ,\n",
      "       0.00444222, 0.00770896, 0.01290572, 0.01179128, 0.00622496,\n",
      "       0.00692608, 0.01095548, 0.02318288, 0.00501536, 0.01115145,\n",
      "       0.00612087, 0.01836174, 0.0160954 , 0.01646574, 0.00910406,\n",
      "       0.01111272, 0.00474569, 0.00435135, 0.00400876, 0.00661224,\n",
      "       0.00964084, 0.01784864, 0.01194077, 0.010614  , 0.00736399,\n",
      "       0.01238628, 0.00925848, 0.00944911, 0.01096137, 0.01075231,\n",
      "       0.0099854 , 0.00750349, 0.00379325, 0.00867083, 0.00938577,\n",
      "       0.01173852, 0.00709639, 0.00897813, 0.01206978, 0.00830605,\n",
      "       0.01103235, 0.00738215, 0.00743079, 0.0056236 , 0.00844829,\n",
      "       0.01825138, 0.00903789, 0.00567337, 0.01047744, 0.01537989]), 'param_colsample_bytree': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_leraning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1,\n",
      "                   0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1, 0.5, 0.9, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.5, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.2, 'min_child_weight': 4, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 3, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.5}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.3, 'min_child_weight': 4, 'subsample': 1}], 'split0_test_score': array([0.86890968, 0.8690526 , 0.86886199, 0.8688077 , 0.86902234,\n",
      "       0.86882426, 0.86880618, 0.86910535, 0.86876625, 0.86881269,\n",
      "       0.86910667, 0.86875239, 0.86890968, 0.8690526 , 0.86886199,\n",
      "       0.8688077 , 0.86902234, 0.86882426, 0.86880618, 0.86910535,\n",
      "       0.86876625, 0.86881269, 0.86910667, 0.86875239, 0.86890968,\n",
      "       0.8690526 , 0.86886199, 0.8688077 , 0.86902234, 0.86882426,\n",
      "       0.86880618, 0.86910535, 0.86876625, 0.86881269, 0.86910667,\n",
      "       0.86875239, 0.86890968, 0.8690526 , 0.86886199, 0.8688077 ,\n",
      "       0.86902234, 0.86882426, 0.86880618, 0.86910535, 0.86876625,\n",
      "       0.86881269, 0.86910667, 0.86875239, 0.86890968, 0.8690526 ,\n",
      "       0.86886199, 0.8688077 , 0.86902234, 0.86882426, 0.86880618,\n",
      "       0.86910535, 0.86876625, 0.86881269, 0.86910667, 0.86875239,\n",
      "       0.8692533 , 0.86917148, 0.86928688, 0.86931881, 0.86920652,\n",
      "       0.86928095, 0.86932212, 0.86923183, 0.86929041, 0.86936395,\n",
      "       0.86924624, 0.86929936, 0.8692533 , 0.86917148, 0.86928688,\n",
      "       0.86931881, 0.86920652, 0.86928095, 0.86932212, 0.86923183,\n",
      "       0.86929041, 0.86936395, 0.86924624, 0.86929936, 0.8692533 ,\n",
      "       0.86917148, 0.86928688, 0.86931881, 0.86920652, 0.86928095,\n",
      "       0.86932212, 0.86923183, 0.86929041, 0.86936395, 0.86924624,\n",
      "       0.86929936, 0.8692533 , 0.86917148, 0.86928688, 0.86931881,\n",
      "       0.86920652, 0.86928095, 0.86932212, 0.86923183, 0.86929041,\n",
      "       0.86936395, 0.86924624, 0.86929936, 0.8692533 , 0.86917148,\n",
      "       0.86928688, 0.86931881, 0.86920652, 0.86928095, 0.86932212,\n",
      "       0.86923183, 0.86929041, 0.86936395, 0.86924624, 0.86929936,\n",
      "       0.86951862, 0.86949252, 0.86930651, 0.86941876, 0.86944828,\n",
      "       0.86932259, 0.86954892, 0.86935021, 0.86931905, 0.86953682,\n",
      "       0.86937287, 0.86934523, 0.86951862, 0.86949252, 0.86930651,\n",
      "       0.86941876, 0.86944828, 0.86932259, 0.86954892, 0.86935021,\n",
      "       0.86931905, 0.86953682, 0.86937287, 0.86934523, 0.86951862,\n",
      "       0.86949252, 0.86930651, 0.86941876, 0.86944828, 0.86932259,\n",
      "       0.86954892, 0.86935021, 0.86931905, 0.86953682, 0.86937287,\n",
      "       0.86934523, 0.86951862, 0.86949252, 0.86930651, 0.86941876,\n",
      "       0.86944828, 0.86932259, 0.86954892, 0.86935021, 0.86931905,\n",
      "       0.86953682, 0.86937287, 0.86934523, 0.86951862, 0.86949252,\n",
      "       0.86930651, 0.86941876, 0.86944828, 0.86932259, 0.86954892,\n",
      "       0.86935021, 0.86931905, 0.86953682, 0.86937287, 0.86934523,\n",
      "       0.86958261, 0.86921462, 0.86933639, 0.86962667, 0.86921035,\n",
      "       0.86946021, 0.86957369, 0.86914653, 0.86945281, 0.86952882,\n",
      "       0.86914069, 0.86949404, 0.86958261, 0.86921462, 0.86933639,\n",
      "       0.86962667, 0.86921035, 0.86946021, 0.86957369, 0.86914653,\n",
      "       0.86945281, 0.86952882, 0.86914069, 0.86949404, 0.86958261,\n",
      "       0.86921462, 0.86933639, 0.86962667, 0.86921035, 0.86946021,\n",
      "       0.86957369, 0.86914653, 0.86945281, 0.86952882, 0.86914069,\n",
      "       0.86949404, 0.86958261, 0.86921462, 0.86933639, 0.86962667,\n",
      "       0.86921035, 0.86946021, 0.86957369, 0.86914653, 0.86945281,\n",
      "       0.86952882, 0.86914069, 0.86949404, 0.86958261, 0.86921462,\n",
      "       0.86933639, 0.86962667, 0.86921035, 0.86946021, 0.86957369,\n",
      "       0.86914653, 0.86945281, 0.86952882, 0.86914069, 0.86949404]), 'split1_test_score': array([0.86778284, 0.86794289, 0.86785818, 0.86781313, 0.8679092 ,\n",
      "       0.86768129, 0.86792222, 0.8679129 , 0.86786391, 0.86784033,\n",
      "       0.86791719, 0.86786372, 0.86778284, 0.86794289, 0.86785818,\n",
      "       0.86781313, 0.8679092 , 0.86768129, 0.86792222, 0.8679129 ,\n",
      "       0.86786391, 0.86784033, 0.86791719, 0.86786372, 0.86778284,\n",
      "       0.86794289, 0.86785818, 0.86781313, 0.8679092 , 0.86768129,\n",
      "       0.86792222, 0.8679129 , 0.86786391, 0.86784033, 0.86791719,\n",
      "       0.86786372, 0.86778284, 0.86794289, 0.86785818, 0.86781313,\n",
      "       0.8679092 , 0.86768129, 0.86792222, 0.8679129 , 0.86786391,\n",
      "       0.86784033, 0.86791719, 0.86786372, 0.86778284, 0.86794289,\n",
      "       0.86785818, 0.86781313, 0.8679092 , 0.86768129, 0.86792222,\n",
      "       0.8679129 , 0.86786391, 0.86784033, 0.86791719, 0.86786372,\n",
      "       0.86790265, 0.86806747, 0.86806625, 0.86792254, 0.86797062,\n",
      "       0.86797613, 0.86793546, 0.86801771, 0.86798151, 0.86800538,\n",
      "       0.86792399, 0.86802598, 0.86790265, 0.86806747, 0.86806625,\n",
      "       0.86792254, 0.86797062, 0.86797613, 0.86793546, 0.86801771,\n",
      "       0.86798151, 0.86800538, 0.86792399, 0.86802598, 0.86790265,\n",
      "       0.86806747, 0.86806625, 0.86792254, 0.86797062, 0.86797613,\n",
      "       0.86793546, 0.86801771, 0.86798151, 0.86800538, 0.86792399,\n",
      "       0.86802598, 0.86790265, 0.86806747, 0.86806625, 0.86792254,\n",
      "       0.86797062, 0.86797613, 0.86793546, 0.86801771, 0.86798151,\n",
      "       0.86800538, 0.86792399, 0.86802598, 0.86790265, 0.86806747,\n",
      "       0.86806625, 0.86792254, 0.86797062, 0.86797613, 0.86793546,\n",
      "       0.86801771, 0.86798151, 0.86800538, 0.86792399, 0.86802598,\n",
      "       0.86814187, 0.86831024, 0.86826157, 0.86812176, 0.86830754,\n",
      "       0.86817421, 0.86812286, 0.86840893, 0.86814526, 0.8681664 ,\n",
      "       0.8684106 , 0.86812108, 0.86814187, 0.86831024, 0.86826157,\n",
      "       0.86812176, 0.86830754, 0.86817421, 0.86812286, 0.86840893,\n",
      "       0.86814526, 0.8681664 , 0.8684106 , 0.86812108, 0.86814187,\n",
      "       0.86831024, 0.86826157, 0.86812176, 0.86830754, 0.86817421,\n",
      "       0.86812286, 0.86840893, 0.86814526, 0.8681664 , 0.8684106 ,\n",
      "       0.86812108, 0.86814187, 0.86831024, 0.86826157, 0.86812176,\n",
      "       0.86830754, 0.86817421, 0.86812286, 0.86840893, 0.86814526,\n",
      "       0.8681664 , 0.8684106 , 0.86812108, 0.86814187, 0.86831024,\n",
      "       0.86826157, 0.86812176, 0.86830754, 0.86817421, 0.86812286,\n",
      "       0.86840893, 0.86814526, 0.8681664 , 0.8684106 , 0.86812108,\n",
      "       0.86834223, 0.86850679, 0.86829252, 0.86842798, 0.86871273,\n",
      "       0.86828888, 0.86839168, 0.86871272, 0.86829517, 0.86833848,\n",
      "       0.86860822, 0.86827122, 0.86834223, 0.86850679, 0.86829252,\n",
      "       0.86842798, 0.86871273, 0.86828888, 0.86839168, 0.86871272,\n",
      "       0.86829517, 0.86833848, 0.86860822, 0.86827122, 0.86834223,\n",
      "       0.86850679, 0.86829252, 0.86842798, 0.86871273, 0.86828888,\n",
      "       0.86839168, 0.86871272, 0.86829517, 0.86833848, 0.86860822,\n",
      "       0.86827122, 0.86834223, 0.86850679, 0.86829252, 0.86842798,\n",
      "       0.86871273, 0.86828888, 0.86839168, 0.86871272, 0.86829517,\n",
      "       0.86833848, 0.86860822, 0.86827122, 0.86834223, 0.86850679,\n",
      "       0.86829252, 0.86842798, 0.86871273, 0.86828888, 0.86839168,\n",
      "       0.86871272, 0.86829517, 0.86833848, 0.86860822, 0.86827122]), 'split2_test_score': array([0.86878223, 0.8689801 , 0.86898821, 0.86880658, 0.86890718,\n",
      "       0.86897503, 0.86902706, 0.86896668, 0.86891861, 0.86900571,\n",
      "       0.86898204, 0.8689092 , 0.86878223, 0.8689801 , 0.86898821,\n",
      "       0.86880658, 0.86890718, 0.86897503, 0.86902706, 0.86896668,\n",
      "       0.86891861, 0.86900571, 0.86898204, 0.8689092 , 0.86878223,\n",
      "       0.8689801 , 0.86898821, 0.86880658, 0.86890718, 0.86897503,\n",
      "       0.86902706, 0.86896668, 0.86891861, 0.86900571, 0.86898204,\n",
      "       0.8689092 , 0.86878223, 0.8689801 , 0.86898821, 0.86880658,\n",
      "       0.86890718, 0.86897503, 0.86902706, 0.86896668, 0.86891861,\n",
      "       0.86900571, 0.86898204, 0.8689092 , 0.86878223, 0.8689801 ,\n",
      "       0.86898821, 0.86880658, 0.86890718, 0.86897503, 0.86902706,\n",
      "       0.86896668, 0.86891861, 0.86900571, 0.86898204, 0.8689092 ,\n",
      "       0.86931115, 0.86919559, 0.86907499, 0.86926616, 0.86918759,\n",
      "       0.86916551, 0.86923449, 0.86934817, 0.86916401, 0.86915382,\n",
      "       0.86936282, 0.86916263, 0.86931115, 0.86919559, 0.86907499,\n",
      "       0.86926616, 0.86918759, 0.86916551, 0.86923449, 0.86934817,\n",
      "       0.86916401, 0.86915382, 0.86936282, 0.86916263, 0.86931115,\n",
      "       0.86919559, 0.86907499, 0.86926616, 0.86918759, 0.86916551,\n",
      "       0.86923449, 0.86934817, 0.86916401, 0.86915382, 0.86936282,\n",
      "       0.86916263, 0.86931115, 0.86919559, 0.86907499, 0.86926616,\n",
      "       0.86918759, 0.86916551, 0.86923449, 0.86934817, 0.86916401,\n",
      "       0.86915382, 0.86936282, 0.86916263, 0.86931115, 0.86919559,\n",
      "       0.86907499, 0.86926616, 0.86918759, 0.86916551, 0.86923449,\n",
      "       0.86934817, 0.86916401, 0.86915382, 0.86936282, 0.86916263,\n",
      "       0.86926162, 0.86935375, 0.86942765, 0.86927511, 0.86935086,\n",
      "       0.86939706, 0.86928694, 0.86924325, 0.86949039, 0.86929255,\n",
      "       0.86914979, 0.86939172, 0.86926162, 0.86935375, 0.86942765,\n",
      "       0.86927511, 0.86935086, 0.86939706, 0.86928694, 0.86924325,\n",
      "       0.86949039, 0.86929255, 0.86914979, 0.86939172, 0.86926162,\n",
      "       0.86935375, 0.86942765, 0.86927511, 0.86935086, 0.86939706,\n",
      "       0.86928694, 0.86924325, 0.86949039, 0.86929255, 0.86914979,\n",
      "       0.86939172, 0.86926162, 0.86935375, 0.86942765, 0.86927511,\n",
      "       0.86935086, 0.86939706, 0.86928694, 0.86924325, 0.86949039,\n",
      "       0.86929255, 0.86914979, 0.86939172, 0.86926162, 0.86935375,\n",
      "       0.86942765, 0.86927511, 0.86935086, 0.86939706, 0.86928694,\n",
      "       0.86924325, 0.86949039, 0.86929255, 0.86914979, 0.86939172,\n",
      "       0.86954042, 0.86938431, 0.86934197, 0.86940503, 0.86938508,\n",
      "       0.86939652, 0.86952212, 0.86943971, 0.86937548, 0.86940753,\n",
      "       0.8693949 , 0.86947558, 0.86954042, 0.86938431, 0.86934197,\n",
      "       0.86940503, 0.86938508, 0.86939652, 0.86952212, 0.86943971,\n",
      "       0.86937548, 0.86940753, 0.8693949 , 0.86947558, 0.86954042,\n",
      "       0.86938431, 0.86934197, 0.86940503, 0.86938508, 0.86939652,\n",
      "       0.86952212, 0.86943971, 0.86937548, 0.86940753, 0.8693949 ,\n",
      "       0.86947558, 0.86954042, 0.86938431, 0.86934197, 0.86940503,\n",
      "       0.86938508, 0.86939652, 0.86952212, 0.86943971, 0.86937548,\n",
      "       0.86940753, 0.8693949 , 0.86947558, 0.86954042, 0.86938431,\n",
      "       0.86934197, 0.86940503, 0.86938508, 0.86939652, 0.86952212,\n",
      "       0.86943971, 0.86937548, 0.86940753, 0.8693949 , 0.86947558]), 'split3_test_score': array([0.86819775, 0.86845706, 0.86788203, 0.86810211, 0.86855019,\n",
      "       0.86787626, 0.86811661, 0.86854942, 0.86790953, 0.8681368 ,\n",
      "       0.86855235, 0.86784626, 0.86819775, 0.86845706, 0.86788203,\n",
      "       0.86810211, 0.86855019, 0.86787626, 0.86811661, 0.86854942,\n",
      "       0.86790953, 0.8681368 , 0.86855235, 0.86784626, 0.86819775,\n",
      "       0.86845706, 0.86788203, 0.86810211, 0.86855019, 0.86787626,\n",
      "       0.86811661, 0.86854942, 0.86790953, 0.8681368 , 0.86855235,\n",
      "       0.86784626, 0.86819775, 0.86845706, 0.86788203, 0.86810211,\n",
      "       0.86855019, 0.86787626, 0.86811661, 0.86854942, 0.86790953,\n",
      "       0.8681368 , 0.86855235, 0.86784626, 0.86819775, 0.86845706,\n",
      "       0.86788203, 0.86810211, 0.86855019, 0.86787626, 0.86811661,\n",
      "       0.86854942, 0.86790953, 0.8681368 , 0.86855235, 0.86784626,\n",
      "       0.86822773, 0.86846942, 0.86808072, 0.86822282, 0.86844311,\n",
      "       0.86806343, 0.86818211, 0.86847928, 0.86808822, 0.86820233,\n",
      "       0.86847279, 0.8680387 , 0.86822773, 0.86846942, 0.86808072,\n",
      "       0.86822282, 0.86844311, 0.86806343, 0.86818211, 0.86847928,\n",
      "       0.86808822, 0.86820233, 0.86847279, 0.8680387 , 0.86822773,\n",
      "       0.86846942, 0.86808072, 0.86822282, 0.86844311, 0.86806343,\n",
      "       0.86818211, 0.86847928, 0.86808822, 0.86820233, 0.86847279,\n",
      "       0.8680387 , 0.86822773, 0.86846942, 0.86808072, 0.86822282,\n",
      "       0.86844311, 0.86806343, 0.86818211, 0.86847928, 0.86808822,\n",
      "       0.86820233, 0.86847279, 0.8680387 , 0.86822773, 0.86846942,\n",
      "       0.86808072, 0.86822282, 0.86844311, 0.86806343, 0.86818211,\n",
      "       0.86847928, 0.86808822, 0.86820233, 0.86847279, 0.8680387 ,\n",
      "       0.86863778, 0.86843613, 0.86851713, 0.86858986, 0.86838907,\n",
      "       0.86856067, 0.86848943, 0.86845066, 0.86855125, 0.86847851,\n",
      "       0.86839736, 0.86854742, 0.86863778, 0.86843613, 0.86851713,\n",
      "       0.86858986, 0.86838907, 0.86856067, 0.86848943, 0.86845066,\n",
      "       0.86855125, 0.86847851, 0.86839736, 0.86854742, 0.86863778,\n",
      "       0.86843613, 0.86851713, 0.86858986, 0.86838907, 0.86856067,\n",
      "       0.86848943, 0.86845066, 0.86855125, 0.86847851, 0.86839736,\n",
      "       0.86854742, 0.86863778, 0.86843613, 0.86851713, 0.86858986,\n",
      "       0.86838907, 0.86856067, 0.86848943, 0.86845066, 0.86855125,\n",
      "       0.86847851, 0.86839736, 0.86854742, 0.86863778, 0.86843613,\n",
      "       0.86851713, 0.86858986, 0.86838907, 0.86856067, 0.86848943,\n",
      "       0.86845066, 0.86855125, 0.86847851, 0.86839736, 0.86854742,\n",
      "       0.8682763 , 0.86848668, 0.86832859, 0.86825137, 0.86848698,\n",
      "       0.86837905, 0.86829891, 0.86849221, 0.86831501, 0.86824312,\n",
      "       0.86849848, 0.86826686, 0.8682763 , 0.86848668, 0.86832859,\n",
      "       0.86825137, 0.86848698, 0.86837905, 0.86829891, 0.86849221,\n",
      "       0.86831501, 0.86824312, 0.86849848, 0.86826686, 0.8682763 ,\n",
      "       0.86848668, 0.86832859, 0.86825137, 0.86848698, 0.86837905,\n",
      "       0.86829891, 0.86849221, 0.86831501, 0.86824312, 0.86849848,\n",
      "       0.86826686, 0.8682763 , 0.86848668, 0.86832859, 0.86825137,\n",
      "       0.86848698, 0.86837905, 0.86829891, 0.86849221, 0.86831501,\n",
      "       0.86824312, 0.86849848, 0.86826686, 0.8682763 , 0.86848668,\n",
      "       0.86832859, 0.86825137, 0.86848698, 0.86837905, 0.86829891,\n",
      "       0.86849221, 0.86831501, 0.86824312, 0.86849848, 0.86826686]), 'split4_test_score': array([0.8713542 , 0.87145107, 0.87108188, 0.87143274, 0.87134227,\n",
      "       0.87106473, 0.87133092, 0.87136948, 0.87105105, 0.87114355,\n",
      "       0.87133105, 0.87102256, 0.8713542 , 0.87145107, 0.87108188,\n",
      "       0.87143274, 0.87134227, 0.87106473, 0.87133092, 0.87136948,\n",
      "       0.87105105, 0.87114355, 0.87133105, 0.87102256, 0.8713542 ,\n",
      "       0.87145107, 0.87108188, 0.87143274, 0.87134227, 0.87106473,\n",
      "       0.87133092, 0.87136948, 0.87105105, 0.87114355, 0.87133105,\n",
      "       0.87102256, 0.8713542 , 0.87145107, 0.87108188, 0.87143274,\n",
      "       0.87134227, 0.87106473, 0.87133092, 0.87136948, 0.87105105,\n",
      "       0.87114355, 0.87133105, 0.87102256, 0.8713542 , 0.87145107,\n",
      "       0.87108188, 0.87143274, 0.87134227, 0.87106473, 0.87133092,\n",
      "       0.87136948, 0.87105105, 0.87114355, 0.87133105, 0.87102256,\n",
      "       0.87169394, 0.8716968 , 0.87110791, 0.87143656, 0.87158897,\n",
      "       0.87110278, 0.87142111, 0.87151068, 0.87110709, 0.87141455,\n",
      "       0.87159331, 0.87112392, 0.87169394, 0.8716968 , 0.87110791,\n",
      "       0.87143656, 0.87158897, 0.87110278, 0.87142111, 0.87151068,\n",
      "       0.87110709, 0.87141455, 0.87159331, 0.87112392, 0.87169394,\n",
      "       0.8716968 , 0.87110791, 0.87143656, 0.87158897, 0.87110278,\n",
      "       0.87142111, 0.87151068, 0.87110709, 0.87141455, 0.87159331,\n",
      "       0.87112392, 0.87169394, 0.8716968 , 0.87110791, 0.87143656,\n",
      "       0.87158897, 0.87110278, 0.87142111, 0.87151068, 0.87110709,\n",
      "       0.87141455, 0.87159331, 0.87112392, 0.87169394, 0.8716968 ,\n",
      "       0.87110791, 0.87143656, 0.87158897, 0.87110278, 0.87142111,\n",
      "       0.87151068, 0.87110709, 0.87141455, 0.87159331, 0.87112392,\n",
      "       0.87143076, 0.87161463, 0.87135787, 0.87144618, 0.87153196,\n",
      "       0.87126372, 0.87144511, 0.87161589, 0.8713354 , 0.87151767,\n",
      "       0.87161543, 0.87132663, 0.87143076, 0.87161463, 0.87135787,\n",
      "       0.87144618, 0.87153196, 0.87126372, 0.87144511, 0.87161589,\n",
      "       0.8713354 , 0.87151767, 0.87161543, 0.87132663, 0.87143076,\n",
      "       0.87161463, 0.87135787, 0.87144618, 0.87153196, 0.87126372,\n",
      "       0.87144511, 0.87161589, 0.8713354 , 0.87151767, 0.87161543,\n",
      "       0.87132663, 0.87143076, 0.87161463, 0.87135787, 0.87144618,\n",
      "       0.87153196, 0.87126372, 0.87144511, 0.87161589, 0.8713354 ,\n",
      "       0.87151767, 0.87161543, 0.87132663, 0.87143076, 0.87161463,\n",
      "       0.87135787, 0.87144618, 0.87153196, 0.87126372, 0.87144511,\n",
      "       0.87161589, 0.8713354 , 0.87151767, 0.87161543, 0.87132663,\n",
      "       0.8714419 , 0.87170419, 0.87131274, 0.87144829, 0.87161552,\n",
      "       0.87140458, 0.8714591 , 0.87160169, 0.87139905, 0.87141543,\n",
      "       0.87155577, 0.87140201, 0.8714419 , 0.87170419, 0.87131274,\n",
      "       0.87144829, 0.87161552, 0.87140458, 0.8714591 , 0.87160169,\n",
      "       0.87139905, 0.87141543, 0.87155577, 0.87140201, 0.8714419 ,\n",
      "       0.87170419, 0.87131274, 0.87144829, 0.87161552, 0.87140458,\n",
      "       0.8714591 , 0.87160169, 0.87139905, 0.87141543, 0.87155577,\n",
      "       0.87140201, 0.8714419 , 0.87170419, 0.87131274, 0.87144829,\n",
      "       0.87161552, 0.87140458, 0.8714591 , 0.87160169, 0.87139905,\n",
      "       0.87141543, 0.87155577, 0.87140201, 0.8714419 , 0.87170419,\n",
      "       0.87131274, 0.87144829, 0.87161552, 0.87140458, 0.8714591 ,\n",
      "       0.87160169, 0.87139905, 0.87141543, 0.87155577, 0.87140201]), 'mean_test_score': array([0.86900534, 0.86917674, 0.86893446, 0.86899245, 0.86914624,\n",
      "       0.86888431, 0.8690406 , 0.86918077, 0.86890187, 0.86898782,\n",
      "       0.86917786, 0.86887883, 0.86900534, 0.86917674, 0.86893446,\n",
      "       0.86899245, 0.86914624, 0.86888431, 0.8690406 , 0.86918077,\n",
      "       0.86890187, 0.86898782, 0.86917786, 0.86887883, 0.86900534,\n",
      "       0.86917674, 0.86893446, 0.86899245, 0.86914624, 0.86888431,\n",
      "       0.8690406 , 0.86918077, 0.86890187, 0.86898782, 0.86917786,\n",
      "       0.86887883, 0.86900534, 0.86917674, 0.86893446, 0.86899245,\n",
      "       0.86914624, 0.86888431, 0.8690406 , 0.86918077, 0.86890187,\n",
      "       0.86898782, 0.86917786, 0.86887883, 0.86900534, 0.86917674,\n",
      "       0.86893446, 0.86899245, 0.86914624, 0.86888431, 0.8690406 ,\n",
      "       0.86918077, 0.86890187, 0.86898782, 0.86917786, 0.86887883,\n",
      "       0.86927775, 0.86932015, 0.86912335, 0.86923338, 0.86927936,\n",
      "       0.86911776, 0.86921906, 0.86931753, 0.86912625, 0.86922801,\n",
      "       0.86931983, 0.86913012, 0.86927775, 0.86932015, 0.86912335,\n",
      "       0.86923338, 0.86927936, 0.86911776, 0.86921906, 0.86931753,\n",
      "       0.86912625, 0.86922801, 0.86931983, 0.86913012, 0.86927775,\n",
      "       0.86932015, 0.86912335, 0.86923338, 0.86927936, 0.86911776,\n",
      "       0.86921906, 0.86931753, 0.86912625, 0.86922801, 0.86931983,\n",
      "       0.86913012, 0.86927775, 0.86932015, 0.86912335, 0.86923338,\n",
      "       0.86927936, 0.86911776, 0.86921906, 0.86931753, 0.86912625,\n",
      "       0.86922801, 0.86931983, 0.86913012, 0.86927775, 0.86932015,\n",
      "       0.86912335, 0.86923338, 0.86927936, 0.86911776, 0.86921906,\n",
      "       0.86931753, 0.86912625, 0.86922801, 0.86931983, 0.86913012,\n",
      "       0.86939813, 0.86944145, 0.86937415, 0.86937033, 0.86940554,\n",
      "       0.86934365, 0.86937865, 0.86941379, 0.86936827, 0.86939839,\n",
      "       0.86938921, 0.86934642, 0.86939813, 0.86944145, 0.86937415,\n",
      "       0.86937033, 0.86940554, 0.86934365, 0.86937865, 0.86941379,\n",
      "       0.86936827, 0.86939839, 0.86938921, 0.86934642, 0.86939813,\n",
      "       0.86944145, 0.86937415, 0.86937033, 0.86940554, 0.86934365,\n",
      "       0.86937865, 0.86941379, 0.86936827, 0.86939839, 0.86938921,\n",
      "       0.86934642, 0.86939813, 0.86944145, 0.86937415, 0.86937033,\n",
      "       0.86940554, 0.86934365, 0.86937865, 0.86941379, 0.86936827,\n",
      "       0.86939839, 0.86938921, 0.86934642, 0.86939813, 0.86944145,\n",
      "       0.86937415, 0.86937033, 0.86940554, 0.86934365, 0.86937865,\n",
      "       0.86941379, 0.86936827, 0.86939839, 0.86938921, 0.86934642,\n",
      "       0.86943669, 0.86945932, 0.86932244, 0.86943187, 0.86948213,\n",
      "       0.86938585, 0.8694491 , 0.86947857, 0.8693675 , 0.86938668,\n",
      "       0.86943961, 0.86938195, 0.86943669, 0.86945932, 0.86932244,\n",
      "       0.86943187, 0.86948213, 0.86938585, 0.8694491 , 0.86947857,\n",
      "       0.8693675 , 0.86938668, 0.86943961, 0.86938195, 0.86943669,\n",
      "       0.86945932, 0.86932244, 0.86943187, 0.86948213, 0.86938585,\n",
      "       0.8694491 , 0.86947857, 0.8693675 , 0.86938668, 0.86943961,\n",
      "       0.86938195, 0.86943669, 0.86945932, 0.86932244, 0.86943187,\n",
      "       0.86948213, 0.86938585, 0.8694491 , 0.86947857, 0.8693675 ,\n",
      "       0.86938668, 0.86943961, 0.86938195, 0.86943669, 0.86945932,\n",
      "       0.86932244, 0.86943187, 0.86948213, 0.86938585, 0.8694491 ,\n",
      "       0.86947857, 0.8693675 , 0.86938668, 0.86943961, 0.86938195]), 'std_test_score': array([0.0012428 , 0.00120557, 0.0011735 , 0.00128119, 0.00116453,\n",
      "       0.00120245, 0.00121698, 0.0011703 , 0.00115756, 0.00115924,\n",
      "       0.00115414, 0.00115837, 0.0012428 , 0.00120557, 0.0011735 ,\n",
      "       0.00128119, 0.00116453, 0.00120245, 0.00121698, 0.0011703 ,\n",
      "       0.00115756, 0.00115924, 0.00115414, 0.00115837, 0.0012428 ,\n",
      "       0.00120557, 0.0011735 , 0.00128119, 0.00116453, 0.00120245,\n",
      "       0.00121698, 0.0011703 , 0.00115756, 0.00115924, 0.00115414,\n",
      "       0.00115837, 0.0012428 , 0.00120557, 0.0011735 , 0.00128119,\n",
      "       0.00116453, 0.00120245, 0.00121698, 0.0011703 , 0.00115756,\n",
      "       0.00115924, 0.00115414, 0.00115837, 0.0012428 , 0.00120557,\n",
      "       0.0011735 , 0.00128119, 0.00116453, 0.00120245, 0.00121698,\n",
      "       0.0011703 , 0.00115756, 0.00115924, 0.00115414, 0.00115837,\n",
      "       0.00132914, 0.00126325, 0.00111104, 0.00123304, 0.0012458 ,\n",
      "       0.00112997, 0.00123149, 0.00120087, 0.00112606, 0.00121258,\n",
      "       0.00125234, 0.00113272, 0.00132914, 0.00126325, 0.00111104,\n",
      "       0.00123304, 0.0012458 , 0.00112997, 0.00123149, 0.00120087,\n",
      "       0.00112606, 0.00121258, 0.00125234, 0.00113272, 0.00132914,\n",
      "       0.00126325, 0.00111104, 0.00123304, 0.0012458 , 0.00112997,\n",
      "       0.00123149, 0.00120087, 0.00112606, 0.00121258, 0.00125234,\n",
      "       0.00113272, 0.00132914, 0.00126325, 0.00111104, 0.00123304,\n",
      "       0.0012458 , 0.00112997, 0.00123149, 0.00120087, 0.00112606,\n",
      "       0.00121258, 0.00125234, 0.00113272, 0.00132914, 0.00126325,\n",
      "       0.00111104, 0.00123304, 0.0012458 , 0.00112997, 0.00123149,\n",
      "       0.00120087, 0.00112606, 0.00121258, 0.00125234, 0.00113272,\n",
      "       0.00112437, 0.00118518, 0.00108765, 0.00113918, 0.00116321,\n",
      "       0.00106495, 0.00115546, 0.00116788, 0.00110002, 0.00117351,\n",
      "       0.00117941, 0.00110119, 0.00112437, 0.00118518, 0.00108765,\n",
      "       0.00113918, 0.00116321, 0.00106495, 0.00115546, 0.00116788,\n",
      "       0.00110002, 0.00117351, 0.00117941, 0.00110119, 0.00112437,\n",
      "       0.00118518, 0.00108765, 0.00113918, 0.00116321, 0.00106495,\n",
      "       0.00115546, 0.00116788, 0.00110002, 0.00117351, 0.00117941,\n",
      "       0.00110119, 0.00112437, 0.00118518, 0.00108765, 0.00113918,\n",
      "       0.00116321, 0.00106495, 0.00115546, 0.00116788, 0.00110002,\n",
      "       0.00117351, 0.00117941, 0.00110119, 0.00112437, 0.00118518,\n",
      "       0.00108765, 0.00113918, 0.00116321, 0.00106495, 0.00115546,\n",
      "       0.00116788, 0.00110002, 0.00117351, 0.00117941, 0.00110119,\n",
      "       0.00114868, 0.00117969, 0.00109639, 0.0011407 , 0.00111507,\n",
      "       0.00112231, 0.00114035, 0.00111165, 0.00113068, 0.00114394,\n",
      "       0.00110873, 0.00114709, 0.00114868, 0.00117969, 0.00109639,\n",
      "       0.0011407 , 0.00111507, 0.00112231, 0.00114035, 0.00111165,\n",
      "       0.00113068, 0.00114394, 0.00110873, 0.00114709, 0.00114868,\n",
      "       0.00117969, 0.00109639, 0.0011407 , 0.00111507, 0.00112231,\n",
      "       0.00114035, 0.00111165, 0.00113068, 0.00114394, 0.00110873,\n",
      "       0.00114709, 0.00114868, 0.00117969, 0.00109639, 0.0011407 ,\n",
      "       0.00111507, 0.00112231, 0.00114035, 0.00111165, 0.00113068,\n",
      "       0.00114394, 0.00110873, 0.00114709, 0.00114868, 0.00117969,\n",
      "       0.00109639, 0.0011407 , 0.00111507, 0.00112231, 0.00114035,\n",
      "       0.00111165, 0.00113068, 0.00114394, 0.00110873, 0.00114709]), 'rank_test_score': array([206, 171, 221, 211, 176, 231, 201, 161, 226, 216, 166, 236, 206,\n",
      "       171, 221, 211, 176, 231, 201, 161, 226, 216, 166, 236, 206, 171,\n",
      "       221, 211, 176, 231, 201, 161, 226, 216, 166, 236, 206, 171, 221,\n",
      "       211, 176, 231, 201, 161, 226, 216, 166, 236, 206, 171, 221, 211,\n",
      "       176, 231, 201, 161, 226, 216, 166, 236, 141, 121, 191, 146, 136,\n",
      "       196, 156, 131, 186, 151, 126, 181, 141, 121, 191, 146, 136, 196,\n",
      "       156, 131, 186, 151, 126, 181, 141, 121, 191, 146, 136, 196, 156,\n",
      "       131, 186, 151, 126, 181, 141, 121, 191, 146, 136, 196, 156, 131,\n",
      "       186, 151, 126, 181, 141, 121, 191, 146, 136, 196, 156, 131, 186,\n",
      "       151, 126, 181,  56,  21,  86,  91,  46, 111,  81,  41,  96,  51,\n",
      "        61, 106,  56,  21,  86,  91,  46, 111,  81,  41,  96,  51,  61,\n",
      "       106,  56,  21,  86,  91,  46, 111,  81,  41,  96,  51,  61, 106,\n",
      "        56,  21,  86,  91,  46, 111,  81,  41,  96,  51,  61, 106,  56,\n",
      "        21,  86,  91,  46, 111,  81,  41,  96,  51,  61, 106,  31,  11,\n",
      "       116,  36,   1,  71,  16,   6, 101,  66,  26,  76,  31,  11, 116,\n",
      "        36,   1,  71,  16,   6, 101,  66,  26,  76,  31,  11, 116,  36,\n",
      "         1,  71,  16,   6, 101,  66,  26,  76,  31,  11, 116,  36,   1,\n",
      "        71,  16,   6, 101,  66,  26,  76,  31,  11, 116,  36,   1,  71,\n",
      "        16,   6, 101,  66,  26,  76])} {'colsample_bytree': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9} 0.8694821314969772\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {'leraning_rate':[0.001,0.01,0.1,0.2,0.3],\n",
    "              'subsample':[0.7,0.8,0.9,1],\n",
    "              'colsample_bytree':[0.5,0.7,0.9,1],\n",
    "               'min_child_weight':[1,2,3,4]\n",
    "              }\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(objective='binary:logistic'),\n",
    "                      param_grid=param_test2,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "print(gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = gsearch2.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/5th_sub.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kaggle score 0.86684, maybe we have an overfit here since test score dropped v.s. previous version\n",
    "\n",
    "-> consider to apply more regularization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([79.41061263, 80.43389192, 77.12773519, 36.42378268, 14.19463506,\n",
      "       14.02668471, 14.69469819, 14.03286791, 14.57501812, 13.62874885,\n",
      "       14.18825321, 13.89064875, 14.65360775, 14.24171252, 14.62588592,\n",
      "       13.88227005, 14.18486104, 13.65308342, 14.50321031, 13.97542205,\n",
      "       14.0951077 , 13.92497454, 14.79323473, 14.54110808, 15.89289365,\n",
      "       14.52574983, 15.32281752, 15.03379107, 15.22328448, 14.59536285,\n",
      "       15.14150233, 14.8263463 , 17.09310579, 15.19934769, 16.15319753,\n",
      "       14.71744547, 15.24303122, 14.43678737, 15.49376106, 15.08644938,\n",
      "       16.18690667, 16.11511092, 16.148421  , 14.25028577, 15.1546679 ,\n",
      "       14.59655943, 25.19941278, 69.80134444]), 'std_fit_time': array([ 2.14602843,  2.68863169,  0.31122812, 19.84218118,  0.09117489,\n",
      "        0.33572264,  0.2022447 ,  0.14210625,  0.05535061,  0.22789133,\n",
      "        0.05573474,  0.14059733,  0.19666524,  0.09276068,  0.19191397,\n",
      "        0.06702437,  0.08969908,  0.11618114,  0.24433032,  0.21752664,\n",
      "        0.25317183,  0.11515393,  0.21296295,  0.15435531,  0.46445418,\n",
      "        0.17508276,  0.22634712,  0.38568833,  0.15201926,  0.084145  ,\n",
      "        0.1698841 ,  0.34989713,  0.74587391,  0.21611719,  0.33662006,\n",
      "        0.07846937,  0.17744541,  0.21457113,  0.09778231,  0.1492915 ,\n",
      "        0.14029387,  0.68879312,  1.12304563,  0.16221634,  0.12825012,\n",
      "        0.14243531,  8.3187765 , 16.3149598 ]), 'mean_score_time': array([0.43882585, 0.46256318, 0.44102063, 0.20545068, 0.16296487,\n",
      "       0.16236606, 0.18151546, 0.17652812, 0.17134218, 0.17273817,\n",
      "       0.16416087, 0.161168  , 0.16136818, 0.16515846, 0.16077018,\n",
      "       0.16575708, 0.16755185, 0.17433419, 0.16755233, 0.15917373,\n",
      "       0.1635623 , 0.16695423, 0.1741344 , 0.18590355, 0.16256585,\n",
      "       0.16077061, 0.17912121, 0.17852335, 0.16116996, 0.16755295,\n",
      "       0.16416154, 0.1655582 , 0.17054377, 0.16715322, 0.17114248,\n",
      "       0.16635499, 0.16136928, 0.15199437, 0.1581768 , 0.18809795,\n",
      "       0.16815028, 0.16914759, 0.16176844, 0.1643611 , 0.1591743 ,\n",
      "       0.1633636 , 0.29640789, 0.34926691]), 'std_score_time': array([0.01580705, 0.07818281, 0.04872671, 0.08483233, 0.00240986,\n",
      "       0.00342087, 0.01690225, 0.026612  , 0.01520947, 0.01172317,\n",
      "       0.01372775, 0.00439623, 0.00603072, 0.01113399, 0.00364571,\n",
      "       0.0080626 , 0.00819991, 0.00992121, 0.00574668, 0.00421276,\n",
      "       0.01087102, 0.00957947, 0.01184387, 0.02510907, 0.003278  ,\n",
      "       0.00665693, 0.00875289, 0.01465796, 0.01010409, 0.01011258,\n",
      "       0.00648233, 0.00520081, 0.00843819, 0.01129377, 0.01054752,\n",
      "       0.01545536, 0.00517774, 0.005224  , 0.00135273, 0.03782794,\n",
      "       0.00518534, 0.01177633, 0.00353502, 0.01082289, 0.00325323,\n",
      "       0.00277853, 0.10483347, 0.02160713]), 'param_colsample_bytree': masked_array(data=[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_leraning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1,\n",
      "                   2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2,\n",
      "                   1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1,\n",
      "                   0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1,\n",
      "                   0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1,\n",
      "                   0.9, 1, 0.9, 1, 0.9, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 0, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 1, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 1, 'subsample': 1}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 0.9}, {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.01, 'min_child_weight': 2, 'subsample': 1}], 'split0_test_score': array([0.86949252, 0.86930651, 0.86944828, 0.86932259, 0.86949252,\n",
      "       0.86930651, 0.86944828, 0.86932259, 0.86949252, 0.86930592,\n",
      "       0.86944828, 0.86932229, 0.86949252, 0.86930592, 0.86944828,\n",
      "       0.86932229, 0.86943401, 0.86930443, 0.86944782, 0.8693339 ,\n",
      "       0.86943401, 0.86930443, 0.86944782, 0.8693339 , 0.86921462,\n",
      "       0.86933639, 0.86921035, 0.86946021, 0.86921462, 0.86933639,\n",
      "       0.86921035, 0.86946021, 0.86921462, 0.86933639, 0.86921035,\n",
      "       0.86946021, 0.86921462, 0.86933639, 0.86921035, 0.86946021,\n",
      "       0.86921462, 0.86933639, 0.86920986, 0.86945734, 0.86921462,\n",
      "       0.86933639, 0.86920986, 0.86945734]), 'split1_test_score': array([0.86831024, 0.86826157, 0.86830754, 0.86817421, 0.86831024,\n",
      "       0.86826157, 0.86830754, 0.86817421, 0.8683095 , 0.86828433,\n",
      "       0.86830678, 0.86826048, 0.8683095 , 0.86828433, 0.86830678,\n",
      "       0.86826048, 0.86831025, 0.86817992, 0.86830764, 0.86814595,\n",
      "       0.86831025, 0.86817992, 0.86830764, 0.86814595, 0.86850679,\n",
      "       0.86829252, 0.86871273, 0.86828888, 0.86850679, 0.86829252,\n",
      "       0.86871273, 0.86828888, 0.86851081, 0.86829252, 0.86871414,\n",
      "       0.86828888, 0.86851081, 0.86829252, 0.86871414, 0.86828888,\n",
      "       0.86850949, 0.86825747, 0.86872726, 0.86825745, 0.86850949,\n",
      "       0.86825747, 0.86872726, 0.86825745]), 'split2_test_score': array([0.86935375, 0.86942765, 0.86935086, 0.86939706, 0.86935375,\n",
      "       0.86942765, 0.86935086, 0.86939706, 0.86935368, 0.86942767,\n",
      "       0.8693508 , 0.86939665, 0.86935368, 0.86942767, 0.8693508 ,\n",
      "       0.86939665, 0.86935134, 0.86942612, 0.86934778, 0.86939585,\n",
      "       0.86935134, 0.86942612, 0.86934778, 0.86939585, 0.86938431,\n",
      "       0.86934197, 0.86938508, 0.86939652, 0.86938431, 0.86934197,\n",
      "       0.86938508, 0.86939652, 0.86938431, 0.8693576 , 0.86938508,\n",
      "       0.86939652, 0.86938431, 0.8693576 , 0.86938508, 0.86939652,\n",
      "       0.86952907, 0.86935566, 0.86950924, 0.869347  , 0.86952907,\n",
      "       0.86935566, 0.86950924, 0.869347  ]), 'split3_test_score': array([0.86843613, 0.86851713, 0.86838907, 0.86856067, 0.86843613,\n",
      "       0.86851713, 0.86838907, 0.86856067, 0.86843613, 0.86851713,\n",
      "       0.86838907, 0.86856067, 0.86843613, 0.86851713, 0.86838907,\n",
      "       0.86856067, 0.86839049, 0.86851603, 0.86838737, 0.86857309,\n",
      "       0.86839049, 0.86851603, 0.86838737, 0.86857309, 0.86848668,\n",
      "       0.86832859, 0.86848698, 0.86837905, 0.86848668, 0.86832859,\n",
      "       0.86848698, 0.86837905, 0.86848895, 0.86832825, 0.8684891 ,\n",
      "       0.86837832, 0.86848895, 0.86832825, 0.8684891 , 0.86837832,\n",
      "       0.86849295, 0.86832718, 0.86849272, 0.86837832, 0.86849295,\n",
      "       0.86832718, 0.86849272, 0.86837832]), 'split4_test_score': array([0.87161463, 0.87135787, 0.87153196, 0.87126372, 0.87161463,\n",
      "       0.87135787, 0.87153196, 0.87126372, 0.87161463, 0.87145142,\n",
      "       0.87153125, 0.87126233, 0.87161463, 0.87145142, 0.87153125,\n",
      "       0.87126233, 0.87161463, 0.87144896, 0.87153125, 0.87128132,\n",
      "       0.87161463, 0.87144896, 0.87153125, 0.87128132, 0.87170419,\n",
      "       0.87131274, 0.87161552, 0.87140458, 0.87170419, 0.87131274,\n",
      "       0.87161552, 0.87140458, 0.87170419, 0.87131274, 0.87161552,\n",
      "       0.87140412, 0.87170419, 0.87131274, 0.87161552, 0.87140412,\n",
      "       0.87147143, 0.87131274, 0.87153545, 0.8714037 , 0.87147143,\n",
      "       0.87131274, 0.87153545, 0.8714037 ]), 'mean_test_score': array([0.86944145, 0.86937415, 0.86940554, 0.86934365, 0.86944145,\n",
      "       0.86937415, 0.86940554, 0.86934365, 0.86944129, 0.86939729,\n",
      "       0.86940524, 0.86936049, 0.86944129, 0.86939729, 0.86940524,\n",
      "       0.86936049, 0.86942014, 0.86937509, 0.86940437, 0.86934602,\n",
      "       0.86942014, 0.86937509, 0.86940437, 0.86934602, 0.86945932,\n",
      "       0.86932244, 0.86948213, 0.86938585, 0.86945932, 0.86932244,\n",
      "       0.86948213, 0.86938585, 0.86946058, 0.8693255 , 0.86948284,\n",
      "       0.86938561, 0.86946058, 0.8693255 , 0.86948284, 0.86938561,\n",
      "       0.86944351, 0.86931789, 0.8694949 , 0.86936876, 0.86944351,\n",
      "       0.86931789, 0.8694949 , 0.86936876]), 'std_test_score': array([0.00118518, 0.00108765, 0.00116321, 0.00106495, 0.00118518,\n",
      "       0.00108765, 0.00116321, 0.00106495, 0.00118533, 0.00111733,\n",
      "       0.0011631 , 0.0010459 , 0.00118533, 0.00111733, 0.0011631 ,\n",
      "       0.0010459 , 0.0011927 , 0.00113798, 0.00116326, 0.00107569,\n",
      "       0.0011927 , 0.00113798, 0.00116326, 0.00107569, 0.00117969,\n",
      "       0.00109639, 0.00111507, 0.00112231, 0.00117969, 0.00109639,\n",
      "       0.00111507, 0.00112231, 0.00117866, 0.00109652, 0.0011145 ,\n",
      "       0.00112228, 0.00117866, 0.00109652, 0.0011145 , 0.00112228,\n",
      "       0.0010907 , 0.00110338, 0.00108064, 0.0011283 , 0.0010907 ,\n",
      "       0.00110338, 0.00108064, 0.0011283 ]), 'rank_test_score': array([13, 33, 19, 41, 13, 33, 19, 41, 15, 25, 21, 37, 15, 25, 21, 37, 17,\n",
      "       31, 23, 39, 17, 31, 23, 39,  9, 45,  5, 27,  9, 45,  5, 27,  7, 43,\n",
      "        3, 29,  7, 43,  3, 29, 11, 47,  1, 35, 11, 47,  1, 35])} {'colsample_bytree': 1, 'gamma': 5, 'leraning_rate': 0.001, 'min_child_weight': 2, 'subsample': 0.9} 0.8694949038946387\n"
     ]
    }
   ],
   "source": [
    "## The code below was not implemented because of time. need to work with a more efficient algo around grid search\n",
    "param_test3 = {'leraning_rate':[0.001,0.01],\n",
    "              'subsample':[0.9,1],\n",
    "              'colsample_bytree':[0.9,1],\n",
    "               'min_child_weight':[1,2],\n",
    "               'gamma':[0,1,5]\n",
    "              }\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator=XGBClassifier(objective='binary:logistic'),\n",
    "                      param_grid=param_test3,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "print(gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = gsearch3.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/6th_sub.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to remove columns that have high correlation with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_and_preprocess_drop(resample = 'ROS',scale = True):\n",
    "    #import\n",
    "    train_path = 'G:/Github/GiveMeSomeCredits/data/cs-training.csv'\n",
    "    test_path = 'G:/Github/GiveMeSomeCredits/data/cs-test.csv'\n",
    "    df_train = pd.read_csv(train_path,index_col = 0).reset_index()\n",
    "    df_test = pd.read_csv(test_path,index_col = 0).reset_index()\n",
    "    \n",
    "    #fill in NA\n",
    "    df_train = df_train.fillna(0)\n",
    "    df_test = df_test.fillna(0)\n",
    "    \n",
    "    y = df_train.SeriousDlqin2yrs\n",
    "    X = df_train.drop(columns=['SeriousDlqin2yrs','index','NumberOfTimes90DaysLate',\n",
    "       'NumberOfTime60-89DaysPastDueNotWorse'])\n",
    "    X_test = df_test.drop(columns=['SeriousDlqin2yrs','index','NumberOfTimes90DaysLate',\n",
    "       'NumberOfTime60-89DaysPastDueNotWorse'])\n",
    "    \n",
    "    assert resample\n",
    "    if resample == 'ROS':\n",
    "        X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_sample(X,y)\n",
    "    elif resample == \"SMOTE\":\n",
    "        X_resampled, y_resampled = SMOTE(random_state=0).fit_sample(X,y)\n",
    "    \n",
    "    if scale:\n",
    "        scaler = preprocessing.StandardScaler().fit(X_resampled)\n",
    "        X_train = scaler.transform(X_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train = X_resampled\n",
    "    \n",
    "    return X_train,y_resampled,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## also try to use SMOTE instead of ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test = data_import_and_preprocess_drop(resample = 'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([11.17610879, 10.72391882, 11.12424803, 10.68482308, 11.31714458,\n",
      "       10.8733182 , 11.10789108, 10.95589786, 13.40375023, 13.0584744 ,\n",
      "       14.12222967, 14.63266368, 13.95986362, 13.85833502, 13.94410553,\n",
      "       13.49490743, 14.61750455, 14.22674956, 14.70267615, 14.36278582,\n",
      "       15.47580924, 14.13659077, 14.49842296, 14.03186989]), 'std_fit_time': array([0.06828635, 0.09739334, 0.01855081, 0.07453925, 0.09589608,\n",
      "       0.10026715, 0.10869133, 0.07552867, 0.04816042, 0.24204422,\n",
      "       0.15903906, 0.39246433, 0.2928004 , 0.43000904, 0.08654719,\n",
      "       0.14646338, 0.10320006, 0.18996841, 0.05532496, 0.14386678,\n",
      "       0.42421774, 0.04025373, 0.06696673, 0.10219605]), 'mean_score_time': array([0.15837646, 0.15658097, 0.15777802, 0.15877523, 0.15797725,\n",
      "       0.1571795 , 0.15598283, 0.16057115, 0.15219364, 0.15578303,\n",
      "       0.16495838, 0.16017256, 0.15777802, 0.15717998, 0.15817676,\n",
      "       0.15877471, 0.15159473, 0.15478706, 0.15757909, 0.15099602,\n",
      "       0.15678053, 0.14840322, 0.15039816, 0.14780536]), 'std_score_time': array([0.00222133, 0.00275011, 0.00230865, 0.00291767, 0.00184952,\n",
      "       0.00272037, 0.00325321, 0.004231  , 0.00241038, 0.00465192,\n",
      "       0.01222507, 0.00562825, 0.00375322, 0.00391868, 0.00401903,\n",
      "       0.00502239, 0.00871765, 0.0066572 , 0.00688138, 0.00522428,\n",
      "       0.00877191, 0.00589719, 0.00773561, 0.00317854]), 'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_leraning_rate': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
      "                   0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1,\n",
      "                   0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1,\n",
      "                   0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1, 0.9, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.7, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.0001, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.001, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.01, 'subsample': 1}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'leraning_rate': 0.1, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.0001, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.001, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.01, 'subsample': 1}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'leraning_rate': 0.1, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.0001, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.0001, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.001, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.01, 'subsample': 1}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'subsample': 0.9}, {'colsample_bytree': 1, 'leraning_rate': 0.1, 'subsample': 1}], 'split0_test_score': array([0.88874709, 0.88883346, 0.88874709, 0.88883346, 0.88874709,\n",
      "       0.88883346, 0.88874709, 0.88883346, 0.88916608, 0.88949097,\n",
      "       0.88916608, 0.88949097, 0.88916608, 0.88949097, 0.88916608,\n",
      "       0.88949097, 0.88927216, 0.88897291, 0.88927216, 0.88897291,\n",
      "       0.88927216, 0.88897291, 0.88927216, 0.88897291]), 'split1_test_score': array([0.94639264, 0.94615253, 0.94639264, 0.94615253, 0.94639264,\n",
      "       0.94615253, 0.94639264, 0.94615253, 0.94640373, 0.94599066,\n",
      "       0.94640373, 0.94599066, 0.94640373, 0.94599066, 0.94640373,\n",
      "       0.94599066, 0.94653215, 0.94661257, 0.94653215, 0.94661257,\n",
      "       0.94653215, 0.94661257, 0.94653215, 0.94661257]), 'split2_test_score': array([0.94599916, 0.94607251, 0.94599916, 0.94607251, 0.94599916,\n",
      "       0.94607251, 0.94599916, 0.94607251, 0.94593427, 0.94592811,\n",
      "       0.94593427, 0.94592811, 0.94593427, 0.94592811, 0.94593427,\n",
      "       0.94592811, 0.94642599, 0.94630598, 0.94642599, 0.94630598,\n",
      "       0.94642599, 0.94630598, 0.94642599, 0.94630598]), 'split3_test_score': array([0.94599477, 0.94585593, 0.94599477, 0.94585593, 0.94599477,\n",
      "       0.94585593, 0.94599477, 0.94585593, 0.94610541, 0.94573616,\n",
      "       0.94610541, 0.94573616, 0.94610541, 0.94573616, 0.94610541,\n",
      "       0.94573616, 0.94625358, 0.94626095, 0.94625358, 0.94626095,\n",
      "       0.94625358, 0.94626095, 0.94625358, 0.94626095]), 'split4_test_score': array([0.9478123 , 0.94793998, 0.9478123 , 0.94793998, 0.9478123 ,\n",
      "       0.94793998, 0.9478123 , 0.94793998, 0.94812895, 0.94815825,\n",
      "       0.94812895, 0.94815825, 0.94812895, 0.94815825, 0.94812895,\n",
      "       0.94815825, 0.94799265, 0.94806966, 0.94799265, 0.94806966,\n",
      "       0.94799265, 0.94806966, 0.94799265, 0.94806966]), 'mean_test_score': array([0.93498919, 0.93497088, 0.93498919, 0.93497088, 0.93498919,\n",
      "       0.93497088, 0.93498919, 0.93497088, 0.93514769, 0.93506083,\n",
      "       0.93514769, 0.93506083, 0.93514769, 0.93506083, 0.93514769,\n",
      "       0.93506083, 0.93529531, 0.93524442, 0.93529531, 0.93524442,\n",
      "       0.93529531, 0.93524442, 0.93529531, 0.93524442]), 'std_test_score': array([0.02313069, 0.02308081, 0.02313069, 0.02308081, 0.02313069,\n",
      "       0.02308081, 0.02313069, 0.02308081, 0.0230041 , 0.02280209,\n",
      "       0.0230041 , 0.02280209, 0.0230041 , 0.02280209, 0.0230041 ,\n",
      "       0.02280209, 0.02301997, 0.02314518, 0.02301997, 0.02314518,\n",
      "       0.02301997, 0.02314518, 0.02301997, 0.02314518]), 'rank_test_score': array([17, 21, 17, 21, 17, 21, 17, 21,  9, 13,  9, 13,  9, 13,  9, 13,  1,\n",
      "        5,  1,  5,  1,  5,  1,  5])} {'colsample_bytree': 1, 'leraning_rate': 0.0001, 'subsample': 0.9} 0.9352953053414801\n"
     ]
    }
   ],
   "source": [
    "#grid search to optimize parameters\n",
    "param_test1 = {'leraning_rate':[0.0001,0.001,0.01,0.1],\n",
    "              'subsample':[0.9,1],\n",
    "              'colsample_bytree':[0.7,0.9,1]\n",
    "              }\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(objective='binary:logistic'),\n",
    "                      param_grid=param_test1,\n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=-1, cv=5)\n",
    "\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Probability'] = gsearch1.predict_proba(X_test)[:,1]\n",
    "columns_output = ['index','Probability']\n",
    "\n",
    "output_df = pd.DataFrame(df_test[columns_output])\n",
    "output_df = output_df.rename(columns={'index':\"Id\"})\n",
    "\n",
    "save_path = 'G:/Github/GiveMeSomeCredits/output/1st_sub_smote.csv'\n",
    "output_df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the test score is quite bad, need to understand if this is caused by smote or the removal of two columns in the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
